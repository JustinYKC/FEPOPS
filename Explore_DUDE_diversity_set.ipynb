{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the DUDE database for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform preprocessing on the DUDE database.  Assumes that the DUDE database has been downloaded and placed in the path \"data/dude/unprocessed\". Here, we expect directories for each target containing 'actives_final.ism' and 'decoys_final.ism'.\n",
    "It may be beneficial to split the below out of this Jupyter notebook and deploy to HPC or a non interactive environment. To pre-cache descriptors, run cache_mols_from_csv() on the DudePreprocessor object below.\n",
    "\n",
    "The step may also be skipped by downloading the OpenFEPOPS-DUDE data directory created for analysis of the DUDE diversity set from FigShare at https://doi.org/10.6084/m9.figshare.23951445.v1 .  See the OpenFEPOPS README.md for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from fepops import OpenFEPOPS\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "class DudePreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dude_directory: Union[Path, str] = \"data/dude/\",\n",
    "    ) -> None:\n",
    "        print(dude_directory)\n",
    "        print(type(dude_directory))\n",
    "        self.dude_path = Path(dude_directory)\n",
    "        self.dude_unprocessed_path = self.dude_path / Path(\"unprocessed\")\n",
    "        if not self.dude_path.exists():\n",
    "            raise FileNotFoundError(f\"Dude dataset not found in path: {self.dude_path}\")\n",
    "        self.dude_processed_path = self.dude_path / Path(\"processed\")\n",
    "        self.dude_processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.fepops_ob = OpenFEPOPS()\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "    ):\n",
    "        self.process()\n",
    "\n",
    "    def process(\n",
    "        self,\n",
    "        targets: Optional[Union[str, list[str]]] = None,\n",
    "        skip_existing: bool = True,\n",
    "    ):\n",
    "        if targets is None:\n",
    "            dude_targets = [\n",
    "                t.parent.name\n",
    "                for t in self.dude_path.glob(\"unprocessed/*/actives_final.ism\")\n",
    "            ]\n",
    "        else:\n",
    "            if isinstance(targets, str):\n",
    "                targets = [targets]\n",
    "        print(f\"Processing the following DUDE targets: {dude_targets}\")\n",
    "        for target in tqdm(dude_targets, desc=f\"Preparing targets\"):\n",
    "            self.create_dude_target_csv_data(target, skip_existing=skip_existing)\n",
    "\n",
    "    @staticmethod\n",
    "    def _parallel_init_worker_desc_gen_shared_fepops_ob():\n",
    "        global shared_fepops_ob\n",
    "        shared_fepops_ob = OpenFEPOPS()\n",
    "\n",
    "    @staticmethod\n",
    "    def _parallel_get_rdkit_cansmi(s):\n",
    "        global shared_fepops_ob\n",
    "        mol = shared_fepops_ob._mol_from_smiles(s)\n",
    "        if mol is None:\n",
    "            return \"\"\n",
    "        return Chem.MolToSmiles(mol)\n",
    "\n",
    "    def create_dude_target_csv_data(\n",
    "        self,\n",
    "        dude_target: Path,\n",
    "        actives_file: Path = Path(\"actives_final.ism\"),\n",
    "        decoys_file: Path = Path(\"decoys_final.ism\"),\n",
    "        seperator: str = \" \",\n",
    "        skip_existing: bool = True,\n",
    "    ):\n",
    "        target_output_file = self.dude_processed_path / f\"dude_target_{dude_target}.csv\"\n",
    "        if skip_existing and target_output_file.exists():\n",
    "            print(\n",
    "                f\"Found existing {target_output_file}, skipping due to skip_existing = True, rerun as False to regenerate\"\n",
    "            )\n",
    "        actives = pd.read_csv(\n",
    "            self.dude_unprocessed_path / Path(dude_target) / actives_file,\n",
    "            sep=seperator,\n",
    "            header=None,\n",
    "            names=[\"SMILES\", \"DUDEID\", \"CHEMBLID\"],\n",
    "        )\n",
    "        actives[\"Active\"] = 1\n",
    "        decoys = pd.read_csv(\n",
    "            self.dude_unprocessed_path / Path(dude_target) / decoys_file,\n",
    "            sep=seperator,\n",
    "            header=None,\n",
    "            names=[\"SMILES\", \"DUDEID\"],\n",
    "        )\n",
    "        decoys[\"Active\"] = 0\n",
    "        df = pd.concat([actives, decoys]).reset_index().drop(columns=\"index\")\n",
    "        df[\"rdkit_canonical_smiles\"] = tqdm(\n",
    "            mp.Pool(\n",
    "                initializer=self._parallel_init_worker_desc_gen_shared_fepops_ob\n",
    "            ).imap(self._parallel_get_rdkit_cansmi, df.SMILES, chunksize=100),\n",
    "            desc=f\"Generating {dude_target} benchmark file\",\n",
    "            total=len(df),\n",
    "        )\n",
    "        df.to_csv(target_output_file, index=False)\n",
    "\n",
    "    def cache_mols_from_csv(\n",
    "        self,\n",
    "        csv_path: Union[Path, str],\n",
    "        rdkit_canonical_smiles_column_header: str = \"rdkit_canonical_smiles\",\n",
    "    ):\n",
    "        \"\"\"Cache mols from a CSV into a db for faster recall later\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        csv_path : Union[Path, str]\n",
    "            Path of CSV file. If None, then all CSV files in the DUDE datasets\n",
    "            processed path are used.\n",
    "        rdkit_canonical_smiles_column_header : str, optional\n",
    "            _description_, by default \"rdkit_canonical_smiles\"\n",
    "        \"\"\"\n",
    "\n",
    "        from fepops.fepops_persistent import get_persistent_fepops_storage_object\n",
    "\n",
    "        for csv_path in (\n",
    "            [Path(csv_path)]\n",
    "            if csv_path is not None\n",
    "            else self.dude_processed_path.glob(\"dude_target_*.csv\")\n",
    "        ):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if df[rdkit_canonical_smiles_column_header].isnull().values.any():\n",
    "                print(\n",
    "                    f\"Whilst working on caching {csv_path}, the following mol rows did not contain RDKit canonical SMILES:\"\n",
    "                )\n",
    "                print(df[df[rdkit_canonical_smiles_column_header].isnull()])\n",
    "            smiles = [\n",
    "                s\n",
    "                for s in df[rdkit_canonical_smiles_column_header].tolist()\n",
    "                if not pd.isnull(s)\n",
    "            ]\n",
    "            with get_persistent_fepops_storage_object(csv_path.with_suffix(\".db\")) as f:\n",
    "                f.save_descriptors(smiles)\n",
    "\n",
    "dude_preprocessor=DudePreprocessor()\n",
    "dude_preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the DUDE diversity set and obtain mean and standard deviations for each 'standard' set of FEPOPS descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we read in the DUDE diversity set and gather the mean and standard deviation of the produced FEPOPS descriptors and use these values as defaults for scaling (before scoring) all FEPOPS descriptors. Before running this, there should be 8 targets:\n",
    "\n",
    "* akt1\n",
    "* ampc\n",
    "* cp3a4\n",
    "* cxcr4\n",
    "* gcr\n",
    "* hivpr\n",
    "* hivrt\n",
    "* kif11\n",
    "\n",
    "represented by their associated .csv and .db files present in the data/dude/processed/diversity_set/ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/dude/processed/diversity_set/dude_target_kif11.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_hivrt.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_cxcr4.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_ampc.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_gcr.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_cp3a4.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_akt1.csv'), PosixPath('data/dude/processed/diversity_set/dude_target_hivpr.csv')]\n",
      "Working on dude_target_kif11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6966 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6966/6966 [00:05<00:00, 1255.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_hivrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19229/19229 [00:13<00:00, 1378.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_cxcr4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3446/3446 [00:02<00:00, 1555.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_ampc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2898/2898 [00:01<00:00, 1903.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_gcr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 10066/15258 [00:06<00:03, 1631.98it/s][22:53:46] Explicit valence for atom # 12 N, 5, is greater than permitted\n",
      "[22:53:46] Explicit valence for atom # 12 N, 5, is greater than permitted\n",
      " 68%|██████▊   | 10394/15258 [00:06<00:03, 1605.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse smiles to a valid molecule, smiles was: N#CC(NC(=O)c1ccccc1)=N1=C(c2ccccc2)C=C(c2ccccc2)C=C1c1ccccc1\n",
      "Failed to make a molecule from N#CC(NC(=O)c1ccccc1)=N1=C(c2ccccc2)C=C(c2ccccc2)C=C1c1ccccc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15258/15258 [00:10<00:00, 1503.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_cp3a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11970/11970 [00:08<00:00, 1350.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_akt1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16743/16743 [00:11<00:00, 1400.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dude_target_hivpr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36286/36286 [00:30<00:00, 1176.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mean:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.28932319,  0.5166312 ,  0.37458883,  0.99913668, -0.04193182,\n",
       "        1.03616917,  0.27327129,  0.99839024,  0.09701198,  1.12969387,\n",
       "        0.23718642,  0.99865705,  0.35968991,  0.6649304 ,  0.4123743 ,\n",
       "        0.99893657,  5.70852885,  6.3707943 ,  6.47354071,  6.26385429,\n",
       "        6.19229367,  6.22946713])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Std:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.35067291, 1.00802116, 0.48380817, 0.02926675, 0.15400475,\n",
       "       0.86220776, 0.44542581, 0.03999429, 0.16085455, 0.92042695,\n",
       "       0.42515847, 0.03655217, 0.35778578, 1.36108994, 0.49210665,\n",
       "       0.03252466, 1.96446927, 2.30792259, 2.5024708 , 2.4155645 ,\n",
       "       2.29434487, 2.31437527])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fepops import OpenFEPOPS\n",
    "from tqdm import tqdm\n",
    "from fepops.fepops_persistent import get_persistent_fepops_storage_object\n",
    "import numpy as np\n",
    "dude_diversity_set_path=Path(\"data/dude/processed/diversity_set/\")\n",
    "diversity_target_files=list(dude_diversity_set_path.glob(\"dude_target_*.csv\"))\n",
    "print(diversity_target_files)\n",
    "descriptors=[]\n",
    "for diversity_target in diversity_target_files:\n",
    "    f=get_persistent_fepops_storage_object(diversity_target.with_suffix(\".db\"))\n",
    "    print(f\"Working on {diversity_target.stem}\")\n",
    "    for (orig_smi, dude_id, chemblid, active_flag, can_smi) in tqdm([l.strip().split(\",\") for l in open(diversity_target).readlines()[1:] if len(l)>3]):\n",
    "        status, retrieved_descriptors=f.get_fepops(can_smi)\n",
    "        if status.value ==1:\n",
    "            for d in retrieved_descriptors:\n",
    "                descriptors.append(d)\n",
    "            \n",
    "descriptors=np.array(descriptors)\n",
    "display(\"Mean:\", descriptors.mean(axis=0))\n",
    "display(\"Std:\", descriptors.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark FEPOPS using the DUDE diversity set\n",
    "Collect AUROC scores and compare against Morgan 2 and RDKit fingeprints\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform imports, define similarity methods (except OpenFEPOPS which will be defined upon target assessment in order to load cached descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8 diversity_set_csv_files : ['dude_target_kif11', 'dude_target_hivrt', 'dude_target_cxcr4', 'dude_target_ampc', 'dude_target_gcr', 'dude_target_cp3a4', 'dude_target_akt1', 'dude_target_hivpr']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from fepops import OpenFEPOPS\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Union, Optional\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from fepops.fepops_persistent import get_persistent_fepops_storage_object\n",
    "from typing import Union, Optional\n",
    "from fepops import OpenFEPOPS\n",
    "from fepops.fepops_persistent import get_persistent_fepops_storage_object\n",
    "from fepops.fepops import GetFepopStatusCode\n",
    "import json\n",
    "import sys\n",
    "\n",
    "open_fepops_object=OpenFEPOPS()\n",
    "\n",
    "@dataclass\n",
    "class SimilarityMethod:\n",
    "    name: str\n",
    "    supports_multiple_candidates: bool\n",
    "    descriptor_calc_func: Optional[Callable] = None\n",
    "    descriptor_score_func: Optional[Callable] = None\n",
    "\n",
    "\n",
    "# OpenFEPOPS will be added to this as a persistent object, reading from a DB of cached\n",
    "# molecules for each target in the diversity set\n",
    "similarity_methods = {\n",
    "    'Morgan 2': SimilarityMethod(\n",
    "        \"Morgan 2\",\n",
    "        False,\n",
    "        lambda x: AllChem.GetMorganFingerprint(x, 2),\n",
    "        lambda x, y: DataStructs.TanimotoSimilarity(x,y),\n",
    "    ),\n",
    "    'MACCS': SimilarityMethod(\n",
    "        \"MACCS\",\n",
    "        False,\n",
    "        lambda x: rdMolDescriptors.GetMACCSKeysFingerprint(x),\n",
    "        lambda x, y: DataStructs.TanimotoSimilarity(x,y),\n",
    "    ),\n",
    "    'RDKit': SimilarityMethod(\n",
    "        \"RDKit\",\n",
    "        False,\n",
    "        lambda x: Chem.RDKFingerprint(x,maxPath=4),\n",
    "        lambda x, y: DataStructs.TanimotoSimilarity(x,y),\n",
    "    ),\n",
    "}\n",
    "\n",
    "diversity_set_csv_files = list(Path(\"data/dude/processed/diversity_set/\").glob(\"dude_target*.csv\"))\n",
    "\n",
    "# Write all CSVs to SMILES files\n",
    "print(f\"Got {len(diversity_set_csv_files)} diversity_set_csv_files : {[f.stem for f in diversity_set_csv_files]}\")\n",
    "for csv_file_path in diversity_set_csv_files:\n",
    "    pd.read_csv(csv_file_path,sep=\",\",\n",
    "        index_col=[0],\n",
    "        header=0,\n",
    "        ).loc[:,['rdkit_canonical_smiles', 'DUDEID']].reset_index().to_csv(csv_file_path.with_suffix(\".smi\"), sep=\" \", index=None, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform AUROC score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_scores_info_df=pd.DataFrame()\n",
    "\n",
    "for csv_file_path in diversity_set_csv_files:\n",
    "    \n",
    "    # We replace the OpenFepops similarity object at each new diversity CSV file\n",
    "    # so that new databases may be loaded for speed of descriptor retrieval.\n",
    "    ofepops_persistent=get_persistent_fepops_storage_object(csv_file_path.with_suffix(\".db\"))\n",
    "    similarity_methods['OpenFEPOPS']=SimilarityMethod(\n",
    "        \"OpenFEPOPS\",\n",
    "        True,\n",
    "        lambda x: ofepops_persistent.get_fepops(x, is_canonical=True),\n",
    "        ofepops_persistent.calc_similarity,\n",
    "    )\n",
    "    \n",
    "    df=pd.read_csv(csv_file_path,sep=\",\",\n",
    "                index_col=[0],\n",
    "                header=0,\n",
    "            ).reset_index()\n",
    "    print(df.head())\n",
    "    descriptors={k:[] for k in similarity_methods.keys()}\n",
    "    smiles_list = df['rdkit_canonical_smiles'].tolist()\n",
    "    labels_list = df['Active'].astype(int).tolist()\n",
    "    problematic_compound_indexes=[]\n",
    "    for sm_name, sm in similarity_methods.items():\n",
    "        # Cache all descriptors for each molecular similarity technique, as some mols may be bad and have to be removed\n",
    "        for smiles_i, smiles in tqdm(enumerate(smiles_list), desc=f\"Caching {sm_name} descriptors for {csv_file_path.stem}\"):\n",
    "            mol_from_smiles=open_fepops_object._mol_from_smiles(smiles)\n",
    "            if mol_from_smiles is None:\n",
    "                problematic_compound_indexes.append(smiles_i)\n",
    "                descriptors[sm_name].append(np.nan)\n",
    "            else:\n",
    "                res = sm.descriptor_calc_func(mol_from_smiles)\n",
    "                if isinstance(res, tuple):\n",
    "                    if res[0]==GetFepopStatusCode.FAILED_RETRIEVED_NONE or res[0]==GetFepopStatusCode.FAILED_TO_GENERATE or res[0]==GetFepopStatusCode.FAILED_TO_RETRIEVE or res[1] is None:\n",
    "                        print(f\"Problem with {smiles}, {res}\")\n",
    "                        problematic_compound_indexes.append(smiles_i)\n",
    "                        descriptors[sm_name].append(np.nan)\n",
    "                    else:                    \n",
    "                        descriptors[sm_name].append(res[-1])\n",
    "                else:\n",
    "                    if res is None:\n",
    "                        problematic_compound_indexes.append(smiles_i)\n",
    "                    descriptors[sm_name].append(res)\n",
    "    # Remove failed molecules from pool of descriptors and labels\n",
    "    for k,v in descriptors.items():\n",
    "        descriptors[k]=[v[ii] for ii in range(len(v)) if ii not in problematic_compound_indexes]\n",
    "    labels_list=[labels_list[ii] for ii in range(len(labels_list)) if ii not in problematic_compound_indexes]\n",
    "    auroc_scores={smn:[] for smn in similarity_methods.keys()}\n",
    "    \n",
    "    info=pd.Series(dtype=object)\n",
    "    for sm_name, sm in similarity_methods.items():\n",
    "        # Remove entries which did not return a mol\n",
    "        info['target']=csv_file_path.stem.replace(\"dude_target_\",\"\")\n",
    "        info['similarity_method']=sm_name\n",
    "        info['smiles_count']=len(smiles_list)\n",
    "        info['actives_count']=np.sum(labels_list)\n",
    "        info['failed_smiles']=len(problematic_compound_indexes)\n",
    "        info['failed_active_smiles']=len([ft for ft in problematic_compound_indexes if labels_list[ft]==1])\n",
    "        for active_i in tqdm(\n",
    "                np.argwhere(np.array(labels_list) == 1).flatten(),\n",
    "                desc=f\"Assessing active recall (AUROC) for {sm.name}\",\n",
    "            ):\n",
    "            if sm.supports_multiple_candidates:\n",
    "                scores = np.array(\n",
    "                    sm.descriptor_score_func(\n",
    "                        descriptors[sm_name][active_i], descriptors[sm_name]\n",
    "                    ),\n",
    "                    dtype=float,\n",
    "                ).flatten()\n",
    "            else:\n",
    "                scores = np.array(\n",
    "                    [\n",
    "                        sm.descriptor_score_func(\n",
    "                            descriptors[sm_name][active_i], descriptors[sm_name][smiles_i]\n",
    "                        )\n",
    "                        for smiles_i in range(len(descriptors[sm_name]))\n",
    "                    ],\n",
    "                    dtype=float,\n",
    "                ).flatten()\n",
    "            \n",
    "            auroc_scores[sm_name].append(roc_auc_score(\n",
    "                np.array(labels_list)[np.argwhere(~np.isnan(scores))],\n",
    "                scores[np.argwhere(~np.isnan(scores))],\n",
    "                )\n",
    "            )\n",
    "        info['average_auroc_score']=np.mean(auroc_scores[sm_name])\n",
    "        info['median_auroc_score']=np.median(auroc_scores[sm_name])\n",
    "        info['q1_auroc_score']=np.percentile(auroc_scores[sm_name],0.25)\n",
    "        info['q3_auroc_score']=np.percentile(auroc_scores[sm_name],0.75)\n",
    "        auroc_scores_info_df=pd.concat([auroc_scores_info_df, info.to_frame().T], ignore_index=True, axis=0)\n",
    "    print(\"Writing to \", csv_file_path.parent)\n",
    "\n",
    "    json.dump(auroc_scores,open(csv_file_path.parent/Path(f\"res_scores_{csv_file_path.stem}.json\"),\"w\"))\n",
    "auroc_scores_info_df.to_csv(csv_file_path.parent/Path(f\"res_df_{csv_file_path.stem}.csv\"))\n",
    "print(auroc_scores_info_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output summary AUROC results table as shown in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>similarity_method</th>\n",
       "      <th>Morgan 2</th>\n",
       "      <th>RDKit</th>\n",
       "      <th>MACCS</th>\n",
       "      <th>OpenFEPOPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akt1</th>\n",
       "      <td>0.835717</td>\n",
       "      <td>0.833538</td>\n",
       "      <td>0.741306</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampc</th>\n",
       "      <td>0.783629</td>\n",
       "      <td>0.659837</td>\n",
       "      <td>0.673310</td>\n",
       "      <td>0.639115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp3a4</th>\n",
       "      <td>0.602774</td>\n",
       "      <td>0.613335</td>\n",
       "      <td>0.581545</td>\n",
       "      <td>0.649807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cxcr4</th>\n",
       "      <td>0.697226</td>\n",
       "      <td>0.592485</td>\n",
       "      <td>0.854251</td>\n",
       "      <td>0.898971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcr</th>\n",
       "      <td>0.670138</td>\n",
       "      <td>0.708350</td>\n",
       "      <td>0.665839</td>\n",
       "      <td>0.616173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hivpr</th>\n",
       "      <td>0.779689</td>\n",
       "      <td>0.759308</td>\n",
       "      <td>0.681237</td>\n",
       "      <td>0.677882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hivrt</th>\n",
       "      <td>0.651011</td>\n",
       "      <td>0.660054</td>\n",
       "      <td>0.669939</td>\n",
       "      <td>0.583981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kif11</th>\n",
       "      <td>0.763058</td>\n",
       "      <td>0.672460</td>\n",
       "      <td>0.667887</td>\n",
       "      <td>0.713152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "similarity_method  Morgan 2     RDKit     MACCS  OpenFEPOPS\n",
       "target                                                     \n",
       "akt1               0.835717  0.833538  0.741306    0.828947\n",
       "ampc               0.783629  0.659837  0.673310    0.639115\n",
       "cp3a4              0.602774  0.613335  0.581545    0.649807\n",
       "cxcr4              0.697226  0.592485  0.854251    0.898971\n",
       "gcr                0.670138  0.708350  0.665839    0.616173\n",
       "hivpr              0.779689  0.759308  0.681237    0.677882\n",
       "hivrt              0.651011  0.660054  0.669939    0.583981\n",
       "kif11              0.763058  0.672460  0.667887    0.713152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.concat([pd.read_csv(f) for f in Path(\"data/dude/processed/diversity_set/\").glob(\"res_df*.csv\")]).pivot(values='average_auroc_score',index='target', columns=['similarity_method'],)[['Morgan 2', 'RDKit', 'MACCS', 'OpenFEPOPS']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output an extended table with information on failed molecules etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACCS</th>\n",
       "      <th>Morgan 2</th>\n",
       "      <th>OpenFEPOPS</th>\n",
       "      <th>RDKit</th>\n",
       "      <th>smiles_count</th>\n",
       "      <th>actives_count</th>\n",
       "      <th>failed_smiles</th>\n",
       "      <th>failed_active_smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akt1</th>\n",
       "      <td>0.741306</td>\n",
       "      <td>0.835717</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.833538</td>\n",
       "      <td>16743</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampc</th>\n",
       "      <td>0.673310</td>\n",
       "      <td>0.783629</td>\n",
       "      <td>0.639115</td>\n",
       "      <td>0.659837</td>\n",
       "      <td>2898</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp3a4</th>\n",
       "      <td>0.581545</td>\n",
       "      <td>0.602774</td>\n",
       "      <td>0.649807</td>\n",
       "      <td>0.613335</td>\n",
       "      <td>11970</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cxcr4</th>\n",
       "      <td>0.854251</td>\n",
       "      <td>0.697226</td>\n",
       "      <td>0.898971</td>\n",
       "      <td>0.592485</td>\n",
       "      <td>3446</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcr</th>\n",
       "      <td>0.665839</td>\n",
       "      <td>0.670138</td>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.708350</td>\n",
       "      <td>15258</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hivpr</th>\n",
       "      <td>0.681237</td>\n",
       "      <td>0.779689</td>\n",
       "      <td>0.677882</td>\n",
       "      <td>0.759308</td>\n",
       "      <td>36286</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hivrt</th>\n",
       "      <td>0.669939</td>\n",
       "      <td>0.651011</td>\n",
       "      <td>0.583981</td>\n",
       "      <td>0.660054</td>\n",
       "      <td>19229</td>\n",
       "      <td>338</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kif11</th>\n",
       "      <td>0.667887</td>\n",
       "      <td>0.763058</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.672460</td>\n",
       "      <td>6966</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MACCS  Morgan 2  OpenFEPOPS     RDKit  smiles_count  actives_count  \\\n",
       "target                                                                          \n",
       "akt1    0.741306  0.835717    0.828947  0.833538         16743            293   \n",
       "ampc    0.673310  0.783629    0.639115  0.659837          2898             48   \n",
       "cp3a4   0.581545  0.602774    0.649807  0.613335         11970            170   \n",
       "cxcr4   0.854251  0.697226    0.898971  0.592485          3446             40   \n",
       "gcr     0.665839  0.670138    0.616173  0.708350         15258            258   \n",
       "hivpr   0.681237  0.779689    0.677882  0.759308         36286            535   \n",
       "hivrt   0.669939  0.651011    0.583981  0.660054         19229            338   \n",
       "kif11   0.667887  0.763058    0.713152  0.672460          6966            116   \n",
       "\n",
       "        failed_smiles  failed_active_smiles  \n",
       "target                                       \n",
       "akt1                0                     0  \n",
       "ampc                1                     0  \n",
       "cp3a4               4                     0  \n",
       "cxcr4               0                     0  \n",
       "gcr                 4                     0  \n",
       "hivpr               1                     1  \n",
       "hivrt               9                     0  \n",
       "kif11               0                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.concat([pd.concat([pd.read_csv(f) for f in Path(\"data/dude/processed/diversity_set/\").glob(\"res_df*.csv\")]).pivot(values='average_auroc_score',index='target', columns=['similarity_method'],),pd.concat([pd.read_csv(f) for f in Path(\"data/dude/processed/diversity_set/\").glob(\"res_df*.csv\")]).query(\"similarity_method=='OpenFEPOPS'\")[['target','smiles_count','actives_count','failed_smiles','failed_active_smiles']].set_index(\"target\")], axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fepops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
